name: "3DAE"
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  hdf5_data_param{
	source: "/home/tarek/Code_Research/Caffe_data_prep/list.txt"
  	batch_size: 10
  }
  include{
	phase: TRAIN
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  hdf5_data_param{
	source: "/home/tarek/Code_Research/Caffe_data_prep/list.txt"
  	batch_size: 10
  }
  include{
	phase: TEST
  }
}


###############conv####################

layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param { # for weights
    lr_mult: 1
    decay_mult: 1
  }
  param { # for bias
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 5
    kernel_size: 5
    kernel_size: 5
    group: 1	
    stride: 1
    weight_filler { 
	type: "gaussian" 
	mean: 0 std: 0.05 
        sparse: 15
    }
    #bias_term: false
#    bias_filler { 
#	type: "constant" 
#	value: 0 
#    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}

###############deconv####################


layer {
  name: "deconv1"
  type: "Deconvolution"
  bottom: "relu1"
  top: "deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    kernel_size: 5
    kernel_size: 5
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler { 
	type: "gaussian" 
	mean: 0 std: 0.05 
        sparse: 15
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "deconv1"
  top: "relu2"
}




###################################

layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "relu2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 9261
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}

###################################

layer {
  name: "flatdata"
  type: "Flatten"
  bottom: "data"
  top: "flatdata"
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "ip1"
  bottom: "flatdata"
  top: "cross_entropy_loss"
  loss_weight: 0
}
layer {
  name: "decode1neuron"
  type: "Sigmoid"
  bottom: "ip1"
  top: "decode1neuron"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "decode1neuron"
  bottom: "flatdata"
  top: "l2_error"
  loss_weight: 1
}



